{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies.\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder , StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv',sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this removes a column for the train data, ot match the test shape. \n",
    "cols_to_test_data = train.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test.csv',sep=\";\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns = cols_to_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.313</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.855</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.959</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.191</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital          education default  housing     loan  \\\n",
       "0   30  blue-collar  married           basic.9y      no      yes       no   \n",
       "1   39     services   single        high.school      no       no       no   \n",
       "2   25     services  married        high.school      no      yes       no   \n",
       "3   38     services  married           basic.9y      no  unknown  unknown   \n",
       "4   47       admin.  married  university.degree      no      yes       no   \n",
       "\n",
       "     contact month day_of_week ...  campaign  pdays  previous     poutcome  \\\n",
       "0   cellular   may         fri ...         2    999         0  nonexistent   \n",
       "1  telephone   may         fri ...         4    999         0  nonexistent   \n",
       "2  telephone   jun         wed ...         1    999         0  nonexistent   \n",
       "3  telephone   jun         fri ...         3    999         0  nonexistent   \n",
       "4   cellular   nov         mon ...         1    999         0  nonexistent   \n",
       "\n",
       "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0         -1.8          92.893          -46.2      1.313       5099.1  no  \n",
       "1          1.1          93.994          -36.4      4.855       5191.0  no  \n",
       "2          1.4          94.465          -41.8      4.962       5228.1  no  \n",
       "3          1.4          94.465          -41.8      4.959       5228.1  no  \n",
       "4         -0.1          93.200          -42.0      4.191       5195.8  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2999, 21), (1120, 20))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instaniating the label enconder to convert categorical data\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list of all columns that are objects, to create numerical values. \n",
    "object_columns = list(train.dtypes[train.dtypes == 'object'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing all object columns to a numerical value to measure. \n",
    "for col in object_columns:\n",
    "    exec(('train[{!r}] = le.fit_transform(train[{!r}])').format(col,col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changed to 0 since they were never contacted\n",
    "train['pdays']= train['pdays'].replace(999,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing The Data for Modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating variables for x and y. \n",
    "X = train.drop(columns='y')\n",
    "y = train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gathering all categorical columns\n",
    "categorical_cols = X[['job','marital','education','default','housing','loan','contact','month','day_of_week','previous',\n",
    "      'poutcome']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dummies for the X and Y variables. (a.k.a OneHotEncoding)\n",
    "We do this for the X variables that are categorical, because in the job column `'blue_collar'` is not 1 > `'services'`. <br />\n",
    "This is done as well for Y because we want them to be a 1 if exists, and a 0 if doesn't. <br />\n",
    "We can reduce this down to 1 column because 1 column can tell us if it  is present or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dums = pd.get_dummies(X,columns=list(categorical_cols.columns),drop_first=True)\n",
    "\n",
    "y_dums = pd.get_dummies(y,drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A class imbalance exists as we can see below. In order to combat this, we are going to use `SMOTE` from `imblearn.over_sampling`. <br/>\n",
    "SMOTE stands for Sampling Minority Oversampling Technique. Ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.88963\n",
       "1    0.11037\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Percentages of each value\n",
    "y_dums[1].value_counts()/ len(y_dums[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import SMOTE to oversample the loan offers since there are so few. \n",
    "sm = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the data to the new oversampled minority amounts.  \n",
    "X_res, y_res = sm.fit_sample(X_dums, y_dums[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking the total of 1's and checking to see the amount over the new sampled y's.\n",
    "y_res.sum()/len(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the data to be able to compare them on the same scale values. \n",
    "ss = StandardScaler()\n",
    "ss_fit = ss.fit_transform(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a test train split to test the data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(ss_fit, y_res, test_size=0.33,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y_res) #preserves class balance between source and split set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the model and reducing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the extra tress classifier. Set a min_samle leaf of 3, this helps to prevent against overfitting on the train\n",
    "clf = ExtraTreesClassifier(n_estimators=10,min_samples_leaf=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using recurisve feature extraction to reduce the amount of features used. \n",
    "rfe = RFECV(clf,n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=None,\n",
       "   estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=3, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "   n_jobs=5, scoring=None, step=1, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the data to the model.\n",
    "rfe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9500283929585462"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using mse to score the data for predictions. \n",
    "rfe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = rfe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the **Matthews correlation coefficient (MCC)**  because it helps us to measure our classification coeffiencts more accurately. When data has an imbalance of 0's vs 1's it causes the interpretation to be too skewed. For example, If you were in a desert, predicting that it's not going to rain is easy because you are more likely to be right due to the imbalance. However if you're in Texas, predicting if it's going to rain or not because more difficult. Therefore, this coeffeienct will tell us, based on the data that we have, how likely are we able to predict how likley someone is to take out a loan, based on our marketing campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9002064197862143"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(y_test,y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speeding up the process\n",
    "Since we hand done the work before, I took what we had done previously and created a function to apply data processing that we had done to the train data. <br/>\n",
    "A validation set, known as test data in this case, will be used to predict and see how we scored against the acutal results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    \n",
    "    #changing all object columns to a numerical value to measure. \n",
    "    object_columns = list(data.dtypes[data.dtypes == 'object'].index)\n",
    "    \n",
    "    for col in object_columns:\n",
    "        exec(('data[{!r}] = le.fit_transform(data[{!r}])').format(col,col))\n",
    "\n",
    "    #changed to 0 since they were never contacted\n",
    "    data['pdays']= data['pdays'].replace(999,0)\n",
    "\n",
    "    categorical_cols = data[['job','marital','education','default','housing','loan','contact','month','day_of_week','previous',\n",
    "          'poutcome']]\n",
    "\n",
    "    X_dums = pd.get_dummies(data,columns=list(categorical_cols.columns),drop_first=True)\n",
    "\n",
    "    ss_fit = ss.fit_transform(X_dums)\n",
    "    return ss_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using our new function to clean the data and label our cleaned and standard scaled test data. \n",
    "test_data = clean_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the prediction using our RFE-ExtraTreeClassifer.\n",
    "predictions = rfe.predict(test_data)\n",
    "\n",
    "#creates a dataframe to view results and export it to a CSV\n",
    "preds = pd.DataFrame(predictions)\n",
    "\n",
    "#creating a range specififed by Kaggle\n",
    "preds['Id'] = range(1,1121)\n",
    "\n",
    "#changing the column names to match the final submission\n",
    "preds.columns = ['prediction','Id']\n",
    "\n",
    "#Putting the data in the proper order. \n",
    "preds = preds[['Id','prediction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the file to CSV for Submssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting the data\n",
    "preds.to_csv('./data/submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
